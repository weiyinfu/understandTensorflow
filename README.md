了解一件事物最好的方式就是实现一遍。  
tensorflow看上去复杂，是因为tensorflow包含了太多可有可无的功能，是过度设计了。它最初的理想并没有这么复杂。  

# level0：一切皆Op
万物皆数
最基本的元素是数，数其实也是一种Op（Operation）。任何操作的输入输出都是数。  
数本身也可以看做一种Op。    
本文件定义了数之间的运算和求导。

# level1：张量是摆成特定形状的Op
逐个操作数字太过繁琐，使用张量把数摆成一定的形状来快速操作它们。张量也是一种Op

# level2：复杂源于简单
基于简单的函数可以构造复杂函数

# level3：图模型
整个计算图是一个有向无环图。有向无环图需要定义依赖管理和结点打包。

# level4：更高级的封装
Optimizer优化器是必需的。

几乎没有什么东西是不可导的，不可导只需要backward返回空。

# TODO
* 神经网络初始化非常重要，好的初始化是成功的一半。看似简简单单，实际上有的初始化能够收敛，有的初始化就无法收敛。
* 输入形状为None的placeholder
* 支持更多形状的张量运算（目前一些运算支持的张量形状有限）
* 模型保存和加载   
只需要保存variable类型的Num，其余的没必要保存  
考虑模型保存和加载，必定要考虑序列化和反序列化
* layers   
全连接、卷积、RNN层的封装
* 模型级的封装
keras中有model，tensorflow中有estimator
* 使用cuda自定义worker来加速计算，或者使用C++重写worker，实现worker只需要实现所有Op子类的forward操作，不需要实现backward操作，构图过程都在python进行就可以，worker只负责运行图
